<!doctype html>
<meta charset="utf-8">
<!-- Mobile Meta -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link rel="stylesheet" href="../static/vendor/bootstrap/css/bootstrap.min.css">
<link rel="stylesheet" href="../static/css/styles.css">
<link rel="stylesheet" href="../static/vendor/font-awesome/css/font-awesome.min.css">
<link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
<title>Spark Structured Streaming | Boontadata Blog</title>
<script type="text/javascript">
    var appInsights=window.appInsights||function(config){
        function i(config){t[config]=function(){var i=arguments;t.queue.push(function(){t[config].apply(t,i)})}}var t={config:config},u=document,e=window,o="script",s="AuthenticatedUserContext",h="start",c="stop",l="Track",a=l+"Event",v=l+"Page",y=u.createElement(o),r,f;y.src=config.url||"https://az416426.vo.msecnd.net/scripts/a/ai.0.js";u.getElementsByTagName(o)[0].parentNode.appendChild(y);try{t.cookie=u.cookie}catch(p){}for(t.queue=[],t.version="1.0",r=["Event","Exception","Metric","PageView","Trace","Dependency"];r.length;)i("track"+r.pop());return i("set"+s),i("clear"+s),i(h+a),i(c+a),i(h+v),i(c+v),i("flush"),config.disableExceptionTracking||(r="onerror",i("_"+r),f=e[r],e[r]=function(config,i,u,e,o){var s=f&&f(config,i,u,e,o);return s!==!0&&t["_"+r](config,i,u,e,o),s}),t
    }({
        instrumentationKey: "5a6e3acc-4022-4ebf-b1d2-5fd0294c1e9d"
    });

    window.appInsights = appInsights;
    appInsights.trackPageView();
</script>
<body>
    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavBar">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
                <a id="boontadata_home_link" class="navbar-brand" href="../" hidden>BoontaData</a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse"  id="myNavBar">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="../">Home</a>
                    </li>
                    
                    <li>
                        <a href="../about/">About</a>
                    </li>
                    
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>
    <header class="intro-header" style="background-color : #4787DA">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="site-heading">
                        <h1>Boontadata</h1>
                        <hr class="small">
                        <span class="subheading">Architectures de traitement de stream</span>
                    </div>
                </div>
            </div>
        </div>
        <div class="social-media">
            <div class="social-media-inner container text-center">
                <ul class="list-inline">
                    <!---
                    <li class="twitter-follow">
                        <a class="github-button" href="https://github.com/boontadata" aria-label="Follow @boontadata on GitHub">Follow @boontadata</a>
                    </li>--><!--//twitter-follow-->
                    <li class="github-watch">
                        <a class="github-button" href="https://github.com/boontadata/boontadata-streams" data-icon="octicon-eye" data-count-href="/boontadata/boontadata-streams/watchers" data-count-api="/repos/boontadata/boontadata-streams#subscribers_count" data-count-aria-label="# watchers on GitHub" aria-label="Watch boontadata/boontadata-streams on GitHub">Watch</a>
                    </li>
                    <li class="twitter-tweet">
                        <a href="https://twitter.com/boontadata" class="twitter-follow-button" data-show-count="false">Follow @boontadata</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
                    </li><!--//twitter-tweet-->
                </ul>
            </div>
        </div>
    </header>
  <div class="container">
      <div class="row">
          <div class="col-md-10 col-md-offset-1">
                
  
  <div class="post-preview">
    
      <h2 id="postToScroll" class="post-title">Spark Structured Streaming</h2>
    
      <p>Dans ce blogpost, nous allons développer notre étude autour d’un moteur de traitement streaming récent: Spark Structured Streaming.
Scalable, tolérant aux pannes, à l’instar de Spark streaming, il se base sur le moteur Spark SQL et permet ainsi la construction plus simple d’applications.</p>
<h3>Principe de fonctionnement</h3>
<p>Concrètement, structured streaming permet à l'utilisateur de traiter la donnée comme s'il s'agissait d'une table qui se remplissait perpétuellement:  chaque nouvelle occurence dans le stream pourrait se traduire par l'ajout d'une nouvelle ligne dans la table. 
Spark permet ainsi de traiter des flux de données en utilisant la même API que pour les traitements batch.</p>
<p><img src="../static/img/sstream/sstream-3.png" alt="spark-structured-streaming-3"></p>
<p>Cette table d'entrée peut ensuite être transformée par une requête qui s'exécute de manière incrémentale pour calculer une table de résultats :</p>
<ul>
<li>L'utilisateur défini un déclencheur (trigger) qui déterminera l'intervalle de temps de mise à jour de la table de résultats. </li>
<li>Lorsque la table de résultats est mise à jour, ces derniers sont persistés sur un stockage externe (écriture de fichiers parquets, sauvegarde dans une base cassandra...). </li>
</ul>
<p><img src="../static/img/sstream/sstream-4.png" alt="spark-structured-streaming-4"></p>
<p>La manière de persister les données est définie pour un "output mode" qui peut prendre les valeurs suivantes :</p>
<ul>
<li>Append: seules les <strong>nouvelles lignes</strong> apparaissant dans notre <em>output table</em> depuis le dernier trigger s'écriront dans le stockage.</li>
<li>Complete: l'ensemble de l'<em>output table</em> sera écrit : c'est le mode que nous utiliserons pour ce démonstrateur</li>
<li>Update: seules les lignes <strong>modifiées</strong> dans notre <em>output table</em> depuis le dernier trigger, seront écrites. (<strong>Non disponible en spark 2.1</strong>)</li>
</ul>
<p>Exemple de comptage des devices par categories de notre simulateur IOT avec le mode <strong>Complete</strong> :</p>
<p><img src="../static/img/sstream/sstream-5.png" alt="spark-structured-streaming-5"></p>
<h3>Atouts et spécificités du modèle Structured Streaming</h3>
<p>Outre la possibilité de travailler sur des flux de données de manière équivalente à ce qui se fait en mode batch, spark structured streaming dispose également de caractéristiques très intéressantes :</p>
<ul>
<li>La gestion d'un <strong>Event-Time</strong> : chaque évènement inséré dans la table d'entrée est accompagné d'une colonne supplémentaire "event-time" qui permet la prise en compte des fenêtres de temps</li>
<li>La gestion du <strong>retard de la donnée</strong> : la table de sortie étant mise à jour de manière incrémentale, une donnée arrivant en "décalage" sera bien prise en compte</li>
<li>La prise en compte de la <strong>tolérance aux pannes</strong> (<em>exactly-once fault tolerance</em>) : un mécanisme de checkpoint est utilisé pour enregistrer les métadonnées correspondant aux données traitées</li>
</ul>
<hr>
<h3>Structured Spark Streaming dans Boontadata:</h3>
<p>Cette série de blogposts visant à comparer différents framework de traitement de données en streaming, le cadre général d'étude reste le même :</p>
<ul>
<li>une source de donnée streaming dans un composant Kafka</li>
<li>le traitement des données avec un framework de traitement de données streaming : ici Spark Structured Streaming (<em>il faut noter que Spark Structured Streaming est toujours en phase “Alpha” de développement, tout comme les API permettant son utilisation.</em>)</li>
<li>les résultats enregistrés dans une base Cassandra pour analyse</li>
</ul>
<p><img src="../static/img/sstream/sstream-1.png" alt="spark-structured-streaming-1"></p>
<p>De manière plus détaillée, la plateforme générique boontadata est constituée des éléments suivants :</p>
<ul>
<li>Simulateur IOT permettant de créer des flux de messages</li>
<li>Système de messagerie distribué Kafka basé sur le principe du "publisher" / "Subscriber"</li>
<li>Base de donnée Cassandra pour le stockage des données et résultats</li>
<li>Service de traitement des flux : Spark Streaming dans le cas de ce blog post</li>
<li>Module de comparaison pour évaluer l'impact et la performance du module de traitement</li>
</ul>
<p><img src="../static/img/sstream/sstream-2.png" alt="spark-structured-streaming-2"></p>
<p>Tous les éléments de la plateforme boontada sont créés dans des containers distincts de manière à apporter un maximum de flexibilité.</p>
<p>Afin de connaître la procédure d’installation, n’hésitez pas à aller sur le lien <a href="https://github.com/boontadata/boontadata-streams/blob/master/doc/procedure_install_running_scenarios.md">suivant</a>.</p>
<p>Ayant déjà traité le fonctionnement de notre environnement et architecture boontadata dans les blogs précédents (voir l'article spark streaming dans la série boontadata),   nous détaillerons ici le code correspondant au nouveau scénario Spark structured Streaming.</p>
<hr>
<h2>Code:</h2>
<p>Pour Spark Structured Streaming, le code est écrit en scala (SStreamingJob.scala). Les principaux éléments du code sont les suivants :</p>
<ul>
<h3>SparkSession et récupération des messages Kafka</h3>
<li> Définition d'une configuration "sparkConf" prenant en compte le nom de notre application et la connexion à la base de données Cassadandra</li>
<script src="https://gist.github.com/BastienBP/7e707482cffb4a5fec9fc27f54ca4fb7.js"></script>
<li> Lecture en streaming des messages provenant des brokers Kafka.  On y renseigne l'adresse des brokers, le topic, le type de lecture, ici "latest", permettant de récupérer les dernier messages du topic </li>
<script src="https://gist.github.com/BastienBP/5d9dfc2dc496f3199e8465a482e6cdd4.js"></script>
</ul><p><h3>Création du dataset</h3>
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</p>
<ul>
<li> On récupère ensuite les champs "value" et "timestamp" des messages (que l'on caste au format String).
On définit une colonne "cols", liste des éléments que l'on veut récupérer de "value".
On réalise ensuite un dataset, issu de la séparation par "|" de chaque ligne.  </li>
<script src="https://gist.github.com/BastienBP/fea5dba294b89a2d9ff3a7f341f20030.js"></script>
=======
<li> Extraction des informations du message : définition des colonnes formant le dataset </li>
<li> Application de la logique business  : somme des mesures sur la fenêtre de temps</li>
<i> Il faut noter que la déduplication des messages n'est pas réalisée en raison d'une limitation du moteur spark structured streaming.  
En effet, à l'heure actuelle, il n'est pas possible de réaliser plus d'une agrégation dans les traitements.  
Pour palier à ce problème, il aurait fallu envoyer le résultat de la déduplication dans un nouveau topic kafka puis traiter ce nouveau message pour faire la somme des mesures de l'IOT.</i>
<script src="https://gist.github.com/lololc/7ea918152380cd1e327bc063aeab89ee.js"></script>

<h3>Application de la requête et enregistrement des données</h3>
<li> Requête : chaque ligne de la table de résultats va être insérée dans Cassandra </li>
<script src="https://gist.github.com/lololc/c1b22eaee7174e1e67994002a5abe45f.js"></script>

<li> Ecriture dans Cassandra : utilisation du Foreach writer </li>
<i> L'output mode a été fixé en "complete" : seul mode adapté dans notre cas (le mode append ne peut être utilisé car les lignes agrégées doivent être modifiées au fur et à mesure de l'arrivée des messages et le mode update n'est pas disponible). Ce mode pourrait poser des problèmes de performances si la taille de la table de sortie devient trop importante.</i>
<script src="https://gist.github.com/lololc/ac9c0a4f75c305e96d201c5e9700e293.js"></script>
>>>>>>> draft-flink
</ul><p>Il pourrait être intéressant de compléter l'étude en faisant varier l'intervalle de déclenchement du trigger. Par défaut, le trigger se déclenche dès que les traitements sont terminés mais l'on peut spécifier une valeur de temps :</p>
<pre><code>// Exemple de déclenchement du trigger toutes les 10 secondes
ds.writeStream.queryName("aggregateStructuredStream")
        .trigger(ProcessingTime("10 seconds"))
        .outputMode("complete")
        .foreach(writer).start
</code></pre>
<hr>
<h2>Résultats</h2>
<p>L'analyse des résultats permet de comparer les valeurs d'agrégation (sur la fenêtre de temps de 5s) réalisées en début de workflow par le simulateur IOT avec celles calculées par le moteur Spark Structured Streaming (sur la base de l'event time)</p>
<p>Exemple de résultats :</p>
<pre><code>Comparing ingest device and downstream for m1_sum
--------------------------------------------------
26 exceptions out of 26
()
Exceptions are:
</code></pre>
<p><img src="../static/img/sstream/results_sss.png" alt="spark-structured-streaming-6"></p>
<p>Ces résultats mettent en évidence les faiblesses actuelles du moteur spark structured streaming. 
En effet, l'impossibilité de réaliser plusieurs agrégations dans un même traitement et la non disponibilité du mode output "update" sont des éléments qui attestent de la jeunesse de ce moteur.</p>

      <p class="post-meta">
          <br>
          Écrit par
          
          Gilles ESSOKI
          
          le 2017-04-25
          
<!--            <span class="post-share"><a href="https://twitter.com/share" class="twitter-share-button" lang="fr" data-text="Spark Structured Streaming" data-url="">Tweet</a></span>
-->       
      </p>
  </div>
<hr>


  <div class="comments">
<div id="disqus_thread"></div>
<script>
  var disqus_config = function() { this.page.identifier = "/spark-structured-streaming"; };
  (function() {
    var d = document, s = d.createElement('script');
    s.src = '//boontadatablog.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>
  Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript"
    rel="nofollow">comments powered by Disqus.</a>
</noscript>
</div>

          </div>
      </div>
  </div>
  <footer>
  </footer>
  <script type="text/javascript" src="../static/vendor/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="../static/vendor/bootstrap/js/bootstrap.min.js"></script>
  <script type="text/javascript" src="../static/js/main.js"></script>
  <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  <script src="https://buttons.github.io/buttons.js"></script>
  <img src="http://tracker.affini-tech.net/pixel.gif"/>
</body>
